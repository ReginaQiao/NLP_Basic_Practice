{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6NwqfMiW4InmeAFihiqjm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReginaQiao/NLP/blob/main/TextGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nETCfpJFR65X"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_text(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        print(f\"Failed to download data from {url}\")\n",
        "        return None\n",
        "\n",
        "# Download the complete works of Shakespeare\n",
        "shakespeare_url = \"https://www.gutenberg.org/ebooks/100.txt.utf-8\"\n",
        "shakespeare_text = download_text(shakespeare_url)\n",
        "\n",
        "# Download Leo Tolstoy's War and Peace\n",
        "war_and_peace_url = \"https://www.gutenberg.org/ebooks/2600.txt.utf-8\"\n",
        "war_and_peace_text = download_text(war_and_peace_url)\n",
        "\n",
        "# Download an English book of Buried Treasure\n",
        "buried_treasure = \"https://www.gutenberg.org/ebooks/33318.txt.utf-8\"\n",
        "buried_treasure_text = download_text(buried_treasure)\n",
        "\n",
        "# Check if the downloads were successful\n",
        "if shakespeare_text is not None:\n",
        "    print(f\"Downloaded {len(shakespeare_text)} characters from Shakespeare's works.\")\n",
        "if war_and_peace_text is not None:\n",
        "    print(f\"Downloaded {len(war_and_peace_text)} characters from War and Peace.\")\n",
        "if buried_treasure_text is not None:\n",
        "    print(f\"Downloaded {len(buried_treasure_text)} characters from Buried Treasure.\")\n",
        "\n",
        "text = shakespeare_text + war_and_peace_text + buried_treasure_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wST2D48oR7kP",
        "outputId": "a7405341-fff1-4dbc-82ad-c8a9c7791e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 5575378 characters from Shakespeare's works.\n",
            "Downloaded 3293593 characters from War and Peace.\n",
            "Downloaded 751489 characters from Buried Treasure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert a character to one-hot encoding\n",
        "def char_to_index_one_hot(text, seq_length, step_size):\n",
        "  chars = sorted(set(text))\n",
        "  vocab_size = len(chars)\n",
        "  char_to_index = dict(((c,i) for i,c in enumerate(chars)))\n",
        "  index_to_char = dict(((i,c)for i,c in enumerate(chars)))\n",
        "\n",
        "  sentences = []\n",
        "  next_character = []\n",
        "\n",
        "  for i in range(0, len(text) - seq_length, step_size):\n",
        "    sentences.append(text[i: i + seq_length])\n",
        "    next_character.append(text[i + seq_length])\n",
        "\n",
        "  x = np.zeros((len(sentences), seq_length, vocab_size))\n",
        "  y = np.zeros((len(sentences), vocab_size))\n",
        "\n",
        "  for i, sentence in enumerate(sentences):\n",
        "    for t, character in enumerate(sentence):\n",
        "      x[i, t, char_to_index[character]] = 1\n",
        "    y[i, char_to_index[character]] = 1\n",
        "\n",
        "\n",
        "  return x, y, vocab_size"
      ],
      "metadata": {
        "id": "bGkGhCrbR7nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get X, y and vocab size\n",
        "seq_length = 32\n",
        "step_size = 1\n",
        "text = text[:100000]\n",
        "X, y, vocab_size = char_to_index_one_hot(text, seq_length, step_size)\n",
        "\n",
        "# Print the vocabulary size and the one-hot encoded sequence\n",
        "print(f\"Vocabulary Size: {vocab_size}\")\n",
        "print(f\"X size: {X.shape}\")\n",
        "print(f\"y size: {y.shape}\")"
      ],
      "metadata": {
        "id": "8Z5OjVLqSJiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ce064b-86cd-4b4b-867c-2f6214855626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 80\n",
            "X size: (99968, 32, 80)\n",
            "y size: (99968, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class textger(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "    super(textger, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out_hn, hn = self.rnn(x)\n",
        "    out = out_hn[:, -1, :]  # last state info\n",
        "    out_linear = self.fc(out)\n",
        "    softmax_ = self.softmax(out_linear)\n",
        "\n",
        "    #print(f\"After RNN layer's output shape: {out_hn.shape}\")\n",
        "    #print(f\"Hidden layer's shape: {hn.shape}\")\n",
        "    #print(f\"After Linear layer's output shape: {out_linear.shape}\")\n",
        "    #print(f\"Softmax shape: {softmax_.shape}\")\n",
        "\n",
        "    return softmax_\n"
      ],
      "metadata": {
        "id": "RbyBkq5F2K4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = vocab_size  # The size of vocabulary (embedding size)\n",
        "hidden_size = 128  # Number of hidden units in the RNN\n",
        "num_layers = 1  # Number of RNN layers\n",
        "output_size = vocab_size  # Output size should match the vocabulary size\n",
        "\n",
        "model = textger(input_size, hidden_size, num_layers, output_size)\n",
        "#model.state_dict()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "2pzp-HOi0vc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb67cfc2-dca7-4526-9631-35fa8f137813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "textger(\n",
            "  (rnn): RNN(80, 128, batch_first=True)\n",
            "  (fc): Linear(in_features=128, out_features=80, bias=True)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "x = torch.rand(1, 32, 80)\n",
        "model(x)"
      ],
      "metadata": {
        "id": "6RHkmLTulW76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd4b467-a8a6-4e71-9ad5-939210d724d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After RNN layer's output shape: torch.Size([1, 32, 128])\n",
            "Hidden layer's shape: torch.Size([1, 1, 128])\n",
            "After Linear layer's output shape: torch.Size([1, 80])\n",
            "Softmax shape: torch.Size([1, 80])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0114, 0.0117, 0.0133, 0.0152, 0.0143, 0.0122, 0.0113, 0.0093, 0.0136,\n",
              "         0.0091, 0.0143, 0.0114, 0.0157, 0.0123, 0.0115, 0.0154, 0.0106, 0.0108,\n",
              "         0.0093, 0.0120, 0.0143, 0.0179, 0.0141, 0.0132, 0.0081, 0.0116, 0.0115,\n",
              "         0.0120, 0.0123, 0.0096, 0.0131, 0.0119, 0.0119, 0.0127, 0.0103, 0.0144,\n",
              "         0.0134, 0.0153, 0.0168, 0.0120, 0.0131, 0.0114, 0.0187, 0.0137, 0.0116,\n",
              "         0.0116, 0.0134, 0.0123, 0.0134, 0.0099, 0.0089, 0.0112, 0.0149, 0.0106,\n",
              "         0.0127, 0.0079, 0.0122, 0.0140, 0.0143, 0.0096, 0.0150, 0.0097, 0.0171,\n",
              "         0.0123, 0.0126, 0.0121, 0.0129, 0.0170, 0.0101, 0.0112, 0.0097, 0.0125,\n",
              "         0.0102, 0.0110, 0.0113, 0.0145, 0.0116, 0.0169, 0.0134, 0.0128]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "nDI5u1j8jQ2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc21bdab-800a-4d3e-ae67-c8eda29895cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (79974, 32, 80)\n",
            "y_train shape: (79974, 80)\n",
            "X_test shape: (19994, 32, 80)\n",
            "y_test shape: (19994, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "k9frD_Wy0vfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "# Create training data batches\n",
        "num_batches = len(X_train) // batch_size\n",
        "X_train_batches = []\n",
        "y_train_batches = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    xbatch = X_train[i * batch_size: (i + 1) * batch_size]\n",
        "    ybatch = y_train[i * batch_size: (i + 1) * batch_size]\n",
        "    X_train_batches.append(xbatch)\n",
        "    y_train_batches.append(ybatch)\n",
        "\n",
        "# Create testing data batches\n",
        "num_batches = len(X_test) // batch_size\n",
        "X_test_batches = []\n",
        "y_test_batches = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    xbatch = X_test[i * batch_size: (i + 1) * batch_size]\n",
        "    ybatch = y_test[i * batch_size: (i + 1) * batch_size]\n",
        "    X_test_batches.append(xbatch)\n",
        "    y_test_batches.append(ybatch)\n"
      ],
      "metadata": {
        "id": "gxp6yWXurF_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_train_batches[0].shape, y_train_batches[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lmLnVGX4Lv_",
        "outputId": "2f60d15f-b8a9-4b04-dfff-a30310e6ab63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((79974, 32, 80), (79974, 80), (100, 32, 80), (100, 80))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape, y_test.shape, X_test_batches[0].shape, y_test_batches[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K19sJALtBxrN",
        "outputId": "76c6334c-5d85-428b-f9db-697b17557e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19994, 32, 80), (19994, 80), (100, 32, 80), (100, 80))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Set the model to training mode\n",
        "model = model.to(device)\n",
        "for epoch in range(2):\n",
        "    train_loss_values = []\n",
        "    train_acc = []\n",
        "    val_loss_values = []\n",
        "    val_error = []\n",
        "    val_acc = []\n",
        "    i = 0\n",
        "    total_step = X_train.shape[0]\n",
        "\n",
        "    model.train()\n",
        "    for X_batch, y_batch in zip(X_train_batches, y_train_batches):\n",
        "      X_batch = torch.Tensor(X_batch)\n",
        "      y_batch = torch.Tensor(y_batch)\n",
        "      pred = model(X_batch)\n",
        "      pred_indices = torch.argmax(pred, dim=1)\n",
        "      y_train_indices = torch.argmax(y_batch, dim=1)\n",
        "      acc = (pred_indices == y_train_indices).sum().item()/y_train_indices.shape[0]\n",
        "      loss_ = loss(pred, y_batch)\n",
        "      i += 1\n",
        "      optimizer.zero_grad()\n",
        "      loss_.backward()\n",
        "      optimizer.step()\n",
        "      if i % 1000 == 0:\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss_.item()))\n",
        "\n",
        "      train_loss_values.append(loss_)\n",
        "      train_acc.append(acc)\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "      for X_test_batch, y_test_batch in zip(X_test_batches, y_test_batches):\n",
        "        X_test_batch = torch.Tensor(X_test_batch)\n",
        "        y_test_batch = torch.Tensor(y_test_batch)\n",
        "        pred_test = model(X_test_batch)\n",
        "        pred_test_indices = torch.argmax(pred_test, dim=1)\n",
        "        y_test_indices = torch.argmax(y_test_batch, dim=1)\n",
        "        acc_test = (pred_test_indices == y_test_indices).sum().item()/y_test_indices.shape[0]\n",
        "        loss_test = loss(pred_test, y_test_batch)\n",
        "\n",
        "    if i % 1000 == 0:\n",
        "      print('Epoch [{}/{}], Step [{}/{}], Test Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss_.item()))\n",
        "    val_loss_values.append(loss_test)\n",
        "    val_acc.append(acc_test)\n"
      ],
      "metadata": {
        "id": "FW3sHR6Y0vkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52e86a2-9898-4349-f729-5e38f0e98b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_values[0].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjfSDTtyoYr5",
        "outputId": "7e9286c3-1b19-4e50-a965-ee16d2eb36d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.203297138214111"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_7JYV04_owxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Validation error subplot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot([i for i in range(num_epochs)], val_loss_values, label='Validation Error', marker='o')\n",
        "plt.plot([i for i in range(num_epochs)], train_loss_values, label='Training Error', marker='x')\n",
        "plt.title('Error vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()\n",
        "\n",
        "# Validation loss subplot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([i for i in range(num_epochs)], train_acc, label='Validation Accuracy', marker='o')\n",
        "plt.plot([i for i in range(num_epochs)], val_acc, label='Training Accuracy', marker='x')\n",
        "plt.title('Accuracy vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "kMdhh0jiPvET",
        "outputId": "60c88c66-7b24-468a-d44d-0147c7b90e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0f9fbaaa2731>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Validation error subplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error vs. Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (799,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E-qcBDd1PvHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4eoSUt6lPvLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ne0yuH38PvOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-Attention"
      ],
      "metadata": {
        "id": "oAcszdAyi8Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get X, y and vocab size\n",
        "seq_length = 128\n",
        "step_size = 1\n",
        "text = text[:100000]\n",
        "X, y, vocab_size = char_to_index_one_hot(text, seq_length, step_size)\n",
        "\n",
        "# Print the vocabulary size and the one-hot encoded sequence\n",
        "print(f\"Vocabulary Size: {vocab_size}\")\n",
        "print(f\"X size: {X.shape}\")\n",
        "print(f\"y size: {y.shape}\")"
      ],
      "metadata": {
        "id": "OtbKAxuz20J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGeneratorTransformer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, nhead, num_encoder_layers):\n",
        "        super(TextGeneratorTransformer, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Transformer layers\n",
        "        self.transformer = nn.Transformer(d_model=input_size, nhead=nhead, num_encoder_layers=num_encoder_layers)\n",
        "        self.fc = nn.Linear(input_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.transformer(x)  # Transformer layer\n",
        "        out_linear = self.fc(out[-1, :, :])  # Get the output from the last time step\n",
        "        softmax_ = self.softmax(out_linear)\n",
        "\n",
        "        return softmax_\n"
      ],
      "metadata": {
        "id": "rLC7tCv0hTm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = vocab_size  # The size of vocabulary (embedding size)\n",
        "hidden_size = 128  # Number of hidden units in the RNN\n",
        "num_layers = 1  # Number of RNN layers\n",
        "output_size = vocab_size  # Output size should match the vocabulary size\n",
        "nhead = 4\n",
        "num_encoder_layers = 1\n",
        "\n",
        "model = TextGeneratorTransformer(input_size, hidden_size, num_layers, output_size, nhead, num_encoder_layers)\n",
        "#model.state_dict()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "ZqJECNndhTq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "o3lAEYBWhTt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "G0j5hzRqSuBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "# Create training data batches\n",
        "num_batches = len(X_train) // batch_size\n",
        "X_train_batches = []\n",
        "y_train_batches = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    xbatch = X_train[i * batch_size: (i + 1) * batch_size]\n",
        "    ybatch = y_train[i * batch_size: (i + 1) * batch_size]\n",
        "    X_train_batches.append(xbatch)\n",
        "    y_train_batches.append(ybatch)\n",
        "\n",
        "# Create testing data batches\n",
        "num_batches = len(X_test) // batch_size\n",
        "X_test_batches = []\n",
        "y_test_batches = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    xbatch = X_test[i * batch_size: (i + 1) * batch_size]\n",
        "    ybatch = y_test[i * batch_size: (i + 1) * batch_size]\n",
        "    X_test_batches.append(xbatch)\n",
        "    y_test_batches.append(ybatch)\n"
      ],
      "metadata": {
        "id": "vBKHOgcuSuEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_train_batches[0].shape, y_train_batches[0].shape"
      ],
      "metadata": {
        "id": "zAV4Uw4sSuHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape, y_test.shape, X_test_batches[0].shape, y_test_batches[0].shape"
      ],
      "metadata": {
        "id": "0T4_WvFyS02l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Set the model to training mode\n",
        "model = model.to(device)\n",
        "for epoch in range(2):\n",
        "    train_loss_values = []\n",
        "    train_acc = []\n",
        "    val_loss_values = []\n",
        "    val_error = []\n",
        "    val_acc = []\n",
        "    i = 0\n",
        "    total_step = X_train.shape[0]\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    for X_batch, y_batch in zip(X_train_batches, y_train_batches):\n",
        "      X_batch = torch.Tensor(X_batch)\n",
        "      y_batch = torch.Tensor(y_batch)\n",
        "      pred = model(X_batch)\n",
        "      pred_indices = torch.argmax(pred, dim=1)\n",
        "      y_train_indices = torch.argmax(y_batch, dim=1)\n",
        "      acc = (pred_indices == y_train_indices).sum().item()/y_train_indices.shape[0]\n",
        "      loss_ = loss(pred, y_batch)\n",
        "      i += 1\n",
        "      optimizer.zero_grad()\n",
        "      loss_.backward()\n",
        "      optimizer.step()\n",
        "      if i % 1000 == 0:\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss_.item()))\n",
        "\n",
        "      train_loss_values.append(loss_)\n",
        "      train_acc.append(acc)\n",
        "\n",
        "\n",
        "      model.eval()\n",
        "      with torch.inference_mode():\n",
        "        for X_test_batch, y_test_batch in zip(X_test_batches, y_test_batches):\n",
        "          X_test_batch = torch.Tensor(X_test_batch)\n",
        "          y_test_batch = torch.Tensor(y_test_batch)\n",
        "          pred_test = model(X_test_batch)\n",
        "          pred_test_indices = torch.argmax(pred_test, dim=1)\n",
        "          y_test_indices = torch.argmax(y_test_batch, dim=1)\n",
        "          acc_test = (pred_test_indices == y_test_indices).sum().item()/y_test_indices.shape[0]\n",
        "          loss_test = loss(pred_test, y_test_batch)\n",
        "\n",
        "      if i % 1000 == 0:\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Test Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss_.item()))\n",
        "      val_loss_values.append(loss_test)\n",
        "      val_acc.append(acc_test)\n"
      ],
      "metadata": {
        "id": "uojURtffS05u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Validation error subplot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot([i for i in range(num_epochs)], val_loss_values, label='Validation Error', marker='o')\n",
        "plt.plot([i for i in range(num_epochs)], train_loss_values, label='Training Error', marker='x')\n",
        "plt.title('Error vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()\n",
        "\n",
        "# Validation loss subplot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([i for i in range(num_epochs)], train_acc, label='Validation Accuracy', marker='o')\n",
        "plt.plot([i for i in range(num_epochs)], val_acc, label='Training Accuracy', marker='x')\n",
        "plt.title('Accuracy vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XQ3EaNlUS081"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0RhbYCInS0_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rS8nzQ4cS1Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dMML2YVaS1Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y0-fG6I7S1IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_TZlCeUfS1Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WO1wSyniS1Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1L07SAcS1Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B0p0-A0PSuKq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}